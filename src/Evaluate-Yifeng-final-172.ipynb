{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/ct2020dl5787/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/ct2020dl5787/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingred_f1(pred, label):\n",
    "    '''\n",
    "    input: \n",
    "        pred: a list of predicted ingredients\n",
    "        label: a list of label ingredients\n",
    "    output: \n",
    "        F-1 score of the prediction\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = [\"tomato\", \"sugar\", \"beef\"]\n",
    "        label = [\"potato\", \"tomato\"]\n",
    "     \n",
    "    out: \n",
    "        0.4\n",
    "    '''\n",
    "    intersection = list(set(pred) & set(label))\n",
    "    precision = len(intersection) / len(pred)\n",
    "    recall = len(intersection) / len(label)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def get_ingred_IOU(pred, label):\n",
    "    '''\n",
    "    input: \n",
    "        pred: a list of predicted ingredients\n",
    "        label: a list of label ingredients\n",
    "    output: \n",
    "        IOU of the prediction\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = [\"tomato\", \"sugar\", \"beef\"]\n",
    "        label = [\"potato\", \"tomato\"]\n",
    "     \n",
    "    out: \n",
    "        0.25\n",
    "    '''\n",
    "    intersection = len(list(set(pred) & set(label)))\n",
    "    union = len(list(set(pred) | set(label)))\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_bleu_n_score(pred, label, n = 4):\n",
    "    \n",
    "    '''\n",
    "    TODO: STEM not added\n",
    "    input: \n",
    "        pred: One string of predict recipe \n",
    "        label: One string of reference recipe\n",
    "        n(optional): up to n-gram.\n",
    "    output: \n",
    "        bleu score\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = \"Add the buttter\"\n",
    "        label = \"Add half butter and mix well\"\n",
    "    out: \n",
    "        0.25\n",
    "    '''\n",
    "    weights = [1/n] * n\n",
    "    pred_list = pred.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    pred_list = [ps.stem(word) for word in pred_list]\n",
    "    label_list = label.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    label_list = [ps.stem(word) for word in label_list]\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([label_list], pred_list, weights)\n",
    "    return BLEUscore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_meteor_score(pred, label):\n",
    "    return meteor_score([label], pred)\n",
    "\n",
    "def read_ingre_vocab(filepath):\n",
    "    '''\n",
    "    input: \n",
    "        filepath of recipe1m_vocab_ingrs.pkl\n",
    "    output: \n",
    "        a list of stemed ingre\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        \"4 large baking potatoes (2 lb./900 g) Safeway 2 pkg For $5.00 thru 02/09\"\"\n",
    "    out: \n",
    "        [\"potato\"]\n",
    "    '''\n",
    "    ingre = pickle.load(open(filepath, \"rb\" ))\n",
    "    result = []\n",
    "    for i in range(1, len(ingre.idx2word)):\n",
    "        word = min(ingre.idx2word[i], key=len)\n",
    "        if \"_\" not in word:\n",
    "            result.append(ps.stem(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word, idx=None):\n",
    "        if idx is None:\n",
    "            if not word in self.word2idx:\n",
    "                self.word2idx[word] = self.idx\n",
    "                self.idx2word[self.idx] = word\n",
    "                self.idx += 1\n",
    "            return self.idx\n",
    "        else:\n",
    "            if not word in self.word2idx:\n",
    "                self.word2idx[word] = idx\n",
    "                if idx in self.idx2word.keys():\n",
    "                    self.idx2word[idx].append(word)\n",
    "                else:\n",
    "                    self.idx2word[idx] = [word]\n",
    "\n",
    "                return idx\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<pad>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ingre_f1(results, ref):\n",
    "    '''\n",
    "    input: \n",
    "        results: a list of candidates ingre list\n",
    "        ref: a list of reference ingre\n",
    "    output: \n",
    "        f1 score\n",
    "    '''\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        score = max(score, get_ingred_f1(result, ref))\n",
    "            \n",
    "    return score\n",
    "\n",
    "\n",
    "def score_ingre_IOU(results, ref):\n",
    "    '''\n",
    "    input: \n",
    "        results: a list of candidates ingre list\n",
    "        ref: a list of reference ingre\n",
    "    output: \n",
    "        IOU score\n",
    "    '''\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        score = max(score, get_ingred_IOU(result, ref))\n",
    "            \n",
    "    return score\n",
    "\n",
    "def show_ingre(df, i):\n",
    "    print (df.iloc[i][\"ingredients\"])\n",
    "    print (df.iloc[i][\"generate_ingre\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "def score_recipe_meteor(generate_recipes, ref):\n",
    "    score = 0\n",
    "    ref = \" \".join(ref)\n",
    "    for recipe in generate_recipes:\n",
    "        joined_recipe = \" \".join(recipe)\n",
    "        score = max(score, get_meteor_score(joined_recipe, ref))\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_blue_n(generate_recipes, ref, n):\n",
    "    score = 0\n",
    "    ref = \" \".join(ref)\n",
    "    for recipe in generate_recipes:\n",
    "        joined_recipe = \" \".join(recipe)\n",
    "        score = max(score, get_bleu_n_score(joined_recipe, ref, n))\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_tokenized_and_stemmed_list(ingre_lists, ingre_vocab):\n",
    "    '''\n",
    "    input: \n",
    "        a list of ingredient str\n",
    "        a list of stemmed reference ingre vocab\n",
    "    output: \n",
    "        a set of indredient\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        \"4 large baking potatoes (2 lb./900 g) Safeway 2 pkg For $5.00 thru 02/09\"\"\n",
    "    out: \n",
    "        [\"potato\"]\n",
    "    '''\n",
    "    result = set()\n",
    "    for ingre_list in ingre_lists:\n",
    "        words = word_tokenize(ingre_list) \n",
    "        for word in words: \n",
    "            result.add(ps.stem(word))\n",
    "            \n",
    "    return result & set(ingre_vocab)\n",
    "\n",
    "\n",
    "def is_recipe_validate(generate_score):\n",
    "    count = 0\n",
    "    for j in range (1):\n",
    "#         if results.iloc[i][\"generate_score\"][j][0] == False:\n",
    "        if generate_score[j][0] == False:\n",
    "            count += 1\n",
    "    if count == 4:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# \"apple?! jfs\".translate(str.maketrans('', '', string.punctuation)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '/home/ct2020dl5787/VireoFood172/vocab172_mapping.csv'\n",
    "chinese_vocab = []\n",
    "mapped_vocab = []\n",
    "with open(vocab_file) as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        chinese_vocab.append(row[0])\n",
    "        mapped_vocab.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "# results = pickle.load(open( \"df_recipe1023_all.pkl\", \"rb\" ))\n",
    "# results = pickle.load(open( \"chinese1720sample_allinfo.pkl\", \"rb\" ))\n",
    "results = pickle.load(open( \"output/transform.pkl\", \"rb\" ))\n",
    "stemmed_ingre = read_ingre_vocab(\"../data/recipe1m_vocab_ingrs.pkl\")\n",
    "df_origin = pickle.load(open( \"df_recipe1023_all.pkl\", \"rb\" ))\n",
    "df_ablation = pickle.load(open( \"output/transform.pkl\", \"rb\" ))\n",
    "true_ingre_dict = pickle.load(open( \"true_ingre_1k.pickle\", \"rb\" ))\n",
    "df_1720 = pickle.load(open( \"output/finetune_1720.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_names</th>\n",
       "      <th>true_onehot</th>\n",
       "      <th>true_top20</th>\n",
       "      <th>ingredients_Chinese</th>\n",
       "      <th>generate_ingre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86_10102721546691.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Crab]</td>\n",
       "      <td>[Parsley, Chinese Parsleycoriander, Dumplings,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140_10_14.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[15, 95, 58, 174, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Crushed pepper, Crushed hot and dry chili, Cr...</td>\n",
       "      <td>[Crushed pepper, Minced green onion, Minced gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_10_2.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[99, 7, 69, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Sliced ham, Egg cake, Brunoise diced lentinus...</td>\n",
       "      <td>[Minced green onion, Minced green onion, Mince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64_0fd9b207887e2199159d73db9cc5a803.jpg</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[125, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Seared green onion, Shredded pepper, Tofu chu...</td>\n",
       "      <td>[Crushed pepper, Minced green onion, Minced gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160_10_13.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[13, 146, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Black sesame, Crushed pepper, Chinese Parsley...</td>\n",
       "      <td>[Minced green onion, Minced green onion, Mince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>109_10_24.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[323, 21, 13, 46, 58, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Black sesame, Chinese Parsleycoriander, Groun...</td>\n",
       "      <td>[Crushed pepper, Crushed hot and dry chili, Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>84_10_2.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[27, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Green vegetables, Stinky tofu]</td>\n",
       "      <td>[Crushed pepper, Lettuce, Minced green onion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>111_10_21.jpg</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 121, 63, 12, 58, 21, 135, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Minced green onion, Hob blocks of carrot, Chi...</td>\n",
       "      <td>[Minced green onion, Minced green onion, Mince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>135_10_10.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[265, 27, 266, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[Green vegetables, Rice noodle, Fried yuba skin]</td>\n",
       "      <td>[Minced green onion, Minced green onion, Mince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>117_10_19.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[171, 125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[Tofu chunks, Spring rolls]</td>\n",
       "      <td>[Chinese Parsleycoriander, Tofu chunks, Minced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1720 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    img_names  \\\n",
       "0                       86_10102721546691.jpg   \n",
       "1                               140_10_14.jpg   \n",
       "2                                100_10_2.jpg   \n",
       "3     64_0fd9b207887e2199159d73db9cc5a803.jpg   \n",
       "4                               160_10_13.jpg   \n",
       "...                                       ...   \n",
       "1715                            109_10_24.jpg   \n",
       "1716                              84_10_2.jpg   \n",
       "1717                            111_10_21.jpg   \n",
       "1718                            135_10_10.jpg   \n",
       "1719                            117_10_19.jpg   \n",
       "\n",
       "                                            true_onehot  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "...                                                 ...   \n",
       "1715  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "1716  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1717  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "1718  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1719  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             true_top20  \\\n",
       "0     [345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1     [15, 95, 58, 174, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "2     [99, 7, 69, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3     [125, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [13, 146, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "...                                                 ...   \n",
       "1715  [323, 21, 13, 46, 58, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1716  [27, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1717  [0, 121, 63, 12, 58, 21, 135, 0, 0, 0, 0, 0, 0...   \n",
       "1718  [265, 27, 266, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1719  [171, 125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                    ingredients_Chinese  \\\n",
       "0                                                [Crab]   \n",
       "1     [Crushed pepper, Crushed hot and dry chili, Cr...   \n",
       "2     [Sliced ham, Egg cake, Brunoise diced lentinus...   \n",
       "3     [Seared green onion, Shredded pepper, Tofu chu...   \n",
       "4     [Black sesame, Crushed pepper, Chinese Parsley...   \n",
       "...                                                 ...   \n",
       "1715  [Black sesame, Chinese Parsleycoriander, Groun...   \n",
       "1716                    [Green vegetables, Stinky tofu]   \n",
       "1717  [Minced green onion, Hob blocks of carrot, Chi...   \n",
       "1718   [Green vegetables, Rice noodle, Fried yuba skin]   \n",
       "1719                        [Tofu chunks, Spring rolls]   \n",
       "\n",
       "                                         generate_ingre  \n",
       "0     [Parsley, Chinese Parsleycoriander, Dumplings,...  \n",
       "1     [Crushed pepper, Minced green onion, Minced gr...  \n",
       "2     [Minced green onion, Minced green onion, Mince...  \n",
       "3     [Crushed pepper, Minced green onion, Minced gr...  \n",
       "4     [Minced green onion, Minced green onion, Mince...  \n",
       "...                                                 ...  \n",
       "1715  [Crushed pepper, Crushed hot and dry chili, Mi...  \n",
       "1716  [Crushed pepper, Lettuce, Minced green onion, ...  \n",
       "1717  [Minced green onion, Minced green onion, Mince...  \n",
       "1718  [Minced green onion, Minced green onion, Mince...  \n",
       "1719  [Chinese Parsleycoriander, Tofu chunks, Minced...  \n",
       "\n",
       "[1720 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.rename(columns={'true_ingredients':'ingredients'}, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://img.sndimg.com/food/image/upload/w_512,h_512,c_fit,fl_progressive,q_95/v1/img/recipes/47/91/49/picaYYmb9.jpg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.iloc[2][\"generate_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ablation_study(df_origin, df_ablation, i, true_ingre_dict):\n",
    "    # Compare two ingre\n",
    "    predicted_ingre = df_origin.iloc[i][\"generate_ingre\"][0]\n",
    "    true_ingre = true_ingre_dict[df_origin.iloc[i][\"url\"]]\n",
    "    \n",
    "    # Compare two instruction\n",
    "    generate_recipe_with_predicted_ingre = df_origin.iloc[i][\"generate_reci\"]\n",
    "    generate_recipe_with_true_ingre = df_ablation.iloc[i][\"generate_reci\"]\n",
    "    print(\"predicted_ingre-----------------------------------------\")\n",
    "    print(predicted_ingre)\n",
    "    print(\"true_ingre----------------------------------------------\")\n",
    "    print(true_ingre)\n",
    "    print(\"generate_recipe_with_predicted_ingre--------------------\")\n",
    "    print(generate_recipe_with_predicted_ingre)\n",
    "    print(\"generate_recipe_with_true_ingre-------------------------\")\n",
    "    print(generate_recipe_with_true_ingre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_ablation_study(df_origin, df_ablation, 21, true_ingre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://img.sndimg.com/food/image/upload/w_512,h_512,c_fit,fl_progressive,q_95/v1/img/recipes/26/09/29/piclnaUDO.jpg'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.iloc[21][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_origin.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36873641832573967\n",
      "0.2425339539461238\n"
     ]
    }
   ],
   "source": [
    "# For 172 only\n",
    "\n",
    "f1_summary = []\n",
    "IOU_summary = []\n",
    "for i in range(0, len(results)):\n",
    "    \n",
    "    # validate\n",
    "    generate_score = results.iloc[i][\"generate_score\"]\n",
    "    if not is_recipe_validate(generate_score):\n",
    "        continue\n",
    "        \n",
    "    # Evaluate the ingredient\n",
    "    generate_ingre = results.iloc[i][\"generate_ingre\"]\n",
    "    reference_ingre = get_tokenized_and_stemmed_list(results.iloc[i][\"ingredients\"], stemmed_ingre)\n",
    "\n",
    "    try:\n",
    "        f1_score = score_ingre_f1(generate_ingre, reference_ingre)\n",
    "        iou_score = score_ingre_IOU(generate_ingre, reference_ingre)\n",
    "\n",
    "        f1_summary.append(f1_score)\n",
    "        IOU_summary.append(iou_score)\n",
    "    except:\n",
    "        print (i)\n",
    "\n",
    "    \n",
    "print(sum(f1_summary)/len(f1_summary))\n",
    "print(sum(IOU_summary)/len(IOU_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3822714563075838\n",
      "0.2520162645266425\n",
      "0.2126551174956491\n",
      "0.0824011311040622\n"
     ]
    }
   ],
   "source": [
    "# For Recipe 1M only\n",
    "\n",
    "n_bleu = 3 # bleu-n score, 4 is default\n",
    "f1_summary = []\n",
    "IOU_summary = []\n",
    "meteor_summary = []\n",
    "bleu_summary = []\n",
    "for i in range(0, len(results)):\n",
    "    \n",
    "    # validate\n",
    "    generate_score = results.iloc[i][\"generate_score\"]\n",
    "    if not is_recipe_validate(generate_score):\n",
    "        continue\n",
    "        \n",
    "    # Evaluate the ingredient\n",
    "    generate_ingre = results.iloc[i][\"generate_ingre\"]\n",
    "    reference_ingre = get_tokenized_and_stemmed_list(results.iloc[i][\"ingredients\"], stemmed_ingre)\n",
    "    f1_score = score_ingre_f1(generate_ingre, reference_ingre)\n",
    "    iou_score = score_ingre_IOU(generate_ingre, reference_ingre)\n",
    "    \n",
    "#     print(\"F-1 score\", f1_score)\n",
    "#     print(\"IOU score\", iou_score)\n",
    "    \n",
    "    # Evaluate the recipe\n",
    "    generate_recipes = results.iloc[i][\"generate_reci\"]\n",
    "    ref_recipe = results.iloc[i][\"instructions\"]\n",
    "    m_score = score_recipe_meteor(generate_recipes, ref_recipe)\n",
    "    bleu_score = score_blue_n(generate_recipes, ref_recipe, n_bleu)\n",
    "#     print(\"Meteor score\", m_score)\n",
    "#     print(\"Bleu score\", bleu_score)\n",
    "\n",
    "#     if(bleu_score < 0.05):\n",
    "#         print (i)\n",
    "#         print (bleu_score)\n",
    "#         print (generate_recipes)\n",
    "#         print (ref_recipe)\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    f1_summary.append(f1_score)\n",
    "    IOU_summary.append(iou_score)\n",
    "    meteor_summary.append(m_score)\n",
    "    bleu_summary.append(bleu_score)\n",
    "    \n",
    "print(sum(f1_summary)/len(f1_summary))\n",
    "print(sum(IOU_summary)/len(IOU_summary))\n",
    "print(sum(meteor_summary)/len(meteor_summary))\n",
    "print(sum(bleu_summary)/len(bleu_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.22894143727771604\n",
    "# 0.30131453447328344\n",
    "# 0.16368592972933632\n",
    "# 0.09660006694603887\n",
    "# 0.05463204076204984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.iloc[2][\"generate_reci\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.iloc[2][\"instructions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation:\n",
    "0.38209121434442705\n",
    "0.2518988218773229\n",
    "0.21262867201302285\n",
    "0.045752426936059604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation:\n",
    "0.36885635410182627\n",
    "0.24263463759368842\n",
    "0.2030833555305791\n",
    "0.03971467392930373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "原版：\n",
    "0.3849248128279484\n",
    "0.2549482903374174\n",
    "0.21105063107297653\n",
    "0.04279394272598328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token of true ingre for 1000\n",
    "true_ingre_1k = {}\n",
    "for i in range(0, len(results)):\n",
    "    reference_ingre = get_tokenized_and_stemmed_list(results.iloc[i][\"ingredients\"], stemmed_ingre)\n",
    "    url = results.iloc[i][\"url\"]\n",
    "    true_ingre_1k[url] = list(reference_ingre)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(true_ingre_1k, open( \"true_ingre_1k.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
