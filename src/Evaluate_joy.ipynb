{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/ct2020dl5787/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/ct2020dl5787/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingred_f1(pred, label):\n",
    "    '''\n",
    "    input: \n",
    "        pred: a list of predicted ingredients\n",
    "        label: a list of label ingredients\n",
    "    output: \n",
    "        F-1 score of the prediction\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = [\"tomato\", \"sugar\", \"beef\"]\n",
    "        label = [\"potato\", \"tomato\"]\n",
    "     \n",
    "    out: \n",
    "        0.4\n",
    "    '''\n",
    "    intersection = list(set(pred) & set(label))\n",
    "    precision = len(intersection) / len(pred)\n",
    "    recall = len(intersection) / len(label)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def get_ingred_IOU(pred, label):\n",
    "    '''\n",
    "    input: \n",
    "        pred: a list of predicted ingredients\n",
    "        label: a list of label ingredients\n",
    "    output: \n",
    "        IOU of the prediction\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = [\"tomato\", \"sugar\", \"beef\"]\n",
    "        label = [\"potato\", \"tomato\"]\n",
    "     \n",
    "    out: \n",
    "        0.25\n",
    "    '''\n",
    "    intersection = len(list(set(pred) & set(label)))\n",
    "    union = len(list(set(pred) | set(label)))\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_bleu_n_score(pred, label, n = 4):\n",
    "    \n",
    "    '''\n",
    "    TODO: STEM not added\n",
    "    input: \n",
    "        pred: One string of predict recipe \n",
    "        label: One string of reference recipe\n",
    "        n(optional): up to n-gram.\n",
    "    output: \n",
    "        bleu score\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        pred = \"Add the buttter\"\n",
    "        label = \"Add half butter and mix well\"\n",
    "    out: \n",
    "        0.25\n",
    "    '''\n",
    "    weights = [1/n] * n\n",
    "    pred_list = pred.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    pred_list = [ps.stem(word) for word in pred_list]\n",
    "    label_list = label.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    label_list = [ps.stem(word) for word in label_list]\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([label_list], pred_list, weights)\n",
    "    return BLEUscore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_meteor_score(pred, label):\n",
    "    return meteor_score([label], pred)\n",
    "\n",
    "def read_ingre_vocab(filepath):\n",
    "    '''\n",
    "    input: \n",
    "        filepath of recipe1m_vocab_ingrs.pkl\n",
    "    output: \n",
    "        a list of stemed ingre\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        \"4 large baking potatoes (2 lb./900 g) Safeway 2 pkg For $5.00 thru 02/09\"\"\n",
    "    out: \n",
    "        [\"potato\"]\n",
    "    '''\n",
    "    ingre = pickle.load(open(filepath, \"rb\" ))\n",
    "    result = []\n",
    "    for i in range(1, len(ingre.idx2word)):\n",
    "        word = min(ingre.idx2word[i], key=len)\n",
    "        if \"_\" not in word:\n",
    "            result.append(ps.stem(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word, idx=None):\n",
    "        if idx is None:\n",
    "            if not word in self.word2idx:\n",
    "                self.word2idx[word] = self.idx\n",
    "                self.idx2word[self.idx] = word\n",
    "                self.idx += 1\n",
    "            return self.idx\n",
    "        else:\n",
    "            if not word in self.word2idx:\n",
    "                self.word2idx[word] = idx\n",
    "                if idx in self.idx2word.keys():\n",
    "                    self.idx2word[idx].append(word)\n",
    "                else:\n",
    "                    self.idx2word[idx] = [word]\n",
    "\n",
    "                return idx\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<pad>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ingre_f1(results, ref):\n",
    "    '''\n",
    "    input: \n",
    "        results: a list of candidates ingre list\n",
    "        ref: a list of reference ingre\n",
    "    output: \n",
    "        f1 score\n",
    "    '''\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        score = max(score, get_ingred_f1(result, ref))\n",
    "            \n",
    "    return score\n",
    "\n",
    "\n",
    "def score_ingre_IOU(results, ref):\n",
    "    '''\n",
    "    input: \n",
    "        results: a list of candidates ingre list\n",
    "        ref: a list of reference ingre\n",
    "    output: \n",
    "        IOU score\n",
    "    '''\n",
    "    score = 0\n",
    "    for result in results:\n",
    "        score = max(score, get_ingred_IOU(result, ref))\n",
    "            \n",
    "    return score\n",
    "\n",
    "def show_ingre(df, i):\n",
    "    print (df.iloc[i][\"ingredients\"])\n",
    "    print (df.iloc[i][\"generate_ingre\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "def score_recipe_meteor(generate_recipes, ref):\n",
    "    score = 0\n",
    "    ref = \" \".join(ref)\n",
    "    for recipe in generate_recipes:\n",
    "        joined_recipe = \" \".join(recipe)\n",
    "        score = max(score, get_meteor_score(joined_recipe, ref))\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_blue_n(generate_recipes, ref, n):\n",
    "    score = 0\n",
    "    ref = \" \".join(ref)\n",
    "    for recipe in generate_recipes:\n",
    "        joined_recipe = \" \".join(recipe)\n",
    "        score = max(score, get_bleu_n_score(joined_recipe, ref, n))\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_tokenized_and_stemmed_list(ingre_lists, ingre_vocab):\n",
    "    '''\n",
    "    input: \n",
    "        a list of ingredient str\n",
    "        a list of stemmed reference ingre vocab\n",
    "    output: \n",
    "        a set of indredient\n",
    "    \n",
    "    i.e.  \n",
    "    in: \n",
    "        \"4 large baking potatoes (2 lb./900 g) Safeway 2 pkg For $5.00 thru 02/09\"\"\n",
    "    out: \n",
    "        [\"potato\"]\n",
    "    '''\n",
    "    result = set()\n",
    "    for ingre_list in ingre_lists:\n",
    "        words = word_tokenize(ingre_list) \n",
    "        for word in words: \n",
    "            result.add(ps.stem(word))\n",
    "            \n",
    "    return result & set(ingre_vocab)\n",
    "\n",
    "\n",
    "def is_recipe_validate(generate_score):\n",
    "    count = 0\n",
    "    for j in range (1):\n",
    "#     for j in range (4):\n",
    "        if generate_score[j][0] == False:\n",
    "            count += 1\n",
    "    if count == 4:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "results = pickle.load(open( \"output/ingr_only_1720.pkl\", \"rb\" ))\n",
    "stemmed_ingre = read_ingre_vocab(\"../data/recipe1m_vocab_ingrs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.rename(columns={'true_ingredients':'ingredients'}, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_names</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_Chinese</th>\n",
       "      <th>generate_ingre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92_075811n2tr1trtvr21vvao.jpg</td>\n",
       "      <td>[scallion, pepper, beef]</td>\n",
       "      <td>[Minced green onion, Shredded pepper, Shredded...</td>\n",
       "      <td>[pepper, oil, onion, clove, soy_sauce, sugar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92_075817xlk22xxxagbk296x.jpg</td>\n",
       "      <td>[scallion, pepper, beef]</td>\n",
       "      <td>[Minced green onion, Shredded pepper, Shredded...</td>\n",
       "      <td>[pepper, oil, onion, clove, beans, salt, tomato]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92_100053030.1.jpg</td>\n",
       "      <td>[scallion, pepper, beef]</td>\n",
       "      <td>[Minced green onion, Shredded pepper, Shredded...</td>\n",
       "      <td>[pepper, onion, oil, chicken, mushroom, salt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92_10_0.jpg</td>\n",
       "      <td>[Parsley, beef]</td>\n",
       "      <td>[Chinese Parsleycoriander, Shredded beef tripe]</td>\n",
       "      <td>[pepper, oil, salt, potato, clove, onion, pars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92_10_1.jpg</td>\n",
       "      <td>[Parsley, chili, garlic, beef]</td>\n",
       "      <td>[Chinese Parsleycoriander, Crushed hot and dry...</td>\n",
       "      <td>[oil, onion, pepper, soy_sauce, sugar, chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>63_10_14.jpg</td>\n",
       "      <td>[tofu, chili]</td>\n",
       "      <td>[Tofu chunks, Chili oil]</td>\n",
       "      <td>[onion, pepper, oil, chicken, clove, tomato, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>63_10_16.jpg</td>\n",
       "      <td>[scallion, tofu, chili]</td>\n",
       "      <td>[Minced green onion, Tofu chunks, Chili oil]</td>\n",
       "      <td>[onion, pepper, oil, soy_sauce, clove, broth, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>63_10_18.jpg</td>\n",
       "      <td>[scallion, pork, tofu, chili]</td>\n",
       "      <td>[Minced green onion, Minced pork, Tofu chunks,...</td>\n",
       "      <td>[onion, pepper, potato, clove, oil, tomato, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>63_10_19.jpg</td>\n",
       "      <td>[scallion, pepper, tofu]</td>\n",
       "      <td>[Minced green onion, Hot and dry pepper, Tofu ...</td>\n",
       "      <td>[onion, oil, soy_sauce, pepper, chicken, water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>63_10_2.jpg</td>\n",
       "      <td>[scallion, tofu, chili]</td>\n",
       "      <td>[Minced green onion, Tofu chunks, Chili oil]</td>\n",
       "      <td>[onion, pepper, potato, oil, soy_sauce, water,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1720 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          img_names                     ingredients  \\\n",
       "0     92_075811n2tr1trtvr21vvao.jpg        [scallion, pepper, beef]   \n",
       "1     92_075817xlk22xxxagbk296x.jpg        [scallion, pepper, beef]   \n",
       "2                92_100053030.1.jpg        [scallion, pepper, beef]   \n",
       "3                       92_10_0.jpg                 [Parsley, beef]   \n",
       "4                       92_10_1.jpg  [Parsley, chili, garlic, beef]   \n",
       "...                             ...                             ...   \n",
       "1715                   63_10_14.jpg                   [tofu, chili]   \n",
       "1716                   63_10_16.jpg         [scallion, tofu, chili]   \n",
       "1717                   63_10_18.jpg   [scallion, pork, tofu, chili]   \n",
       "1718                   63_10_19.jpg        [scallion, pepper, tofu]   \n",
       "1719                    63_10_2.jpg         [scallion, tofu, chili]   \n",
       "\n",
       "                                    ingredients_Chinese  \\\n",
       "0     [Minced green onion, Shredded pepper, Shredded...   \n",
       "1     [Minced green onion, Shredded pepper, Shredded...   \n",
       "2     [Minced green onion, Shredded pepper, Shredded...   \n",
       "3       [Chinese Parsleycoriander, Shredded beef tripe]   \n",
       "4     [Chinese Parsleycoriander, Crushed hot and dry...   \n",
       "...                                                 ...   \n",
       "1715                           [Tofu chunks, Chili oil]   \n",
       "1716       [Minced green onion, Tofu chunks, Chili oil]   \n",
       "1717  [Minced green onion, Minced pork, Tofu chunks,...   \n",
       "1718  [Minced green onion, Hot and dry pepper, Tofu ...   \n",
       "1719       [Minced green onion, Tofu chunks, Chili oil]   \n",
       "\n",
       "                                         generate_ingre  \n",
       "0     [pepper, oil, onion, clove, soy_sauce, sugar, ...  \n",
       "1      [pepper, oil, onion, clove, beans, salt, tomato]  \n",
       "2     [pepper, onion, oil, chicken, mushroom, salt, ...  \n",
       "3     [pepper, oil, salt, potato, clove, onion, pars...  \n",
       "4     [oil, onion, pepper, soy_sauce, sugar, chicken...  \n",
       "...                                                 ...  \n",
       "1715  [onion, pepper, oil, chicken, clove, tomato, w...  \n",
       "1716  [onion, pepper, oil, soy_sauce, clove, broth, ...  \n",
       "1717  [onion, pepper, potato, clove, oil, tomato, sa...  \n",
       "1718  [onion, oil, soy_sauce, pepper, chicken, water...  \n",
       "1719  [onion, pepper, potato, oil, soy_sauce, water,...  \n",
       "\n",
       "[1720 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pepper', 'oil', 'onion', 'clove', 'soy_sauce', 'sugar', 'beans', 'carrot']] {'beef', 'pepper', 'scallion'}\n",
      "0.18181818181818182 0.1\n",
      "[['pepper', 'oil', 'onion', 'clove', 'beans', 'salt', 'tomato']] {'beef', 'pepper', 'scallion'}\n",
      "0.2 0.1111111111111111\n",
      "[['pepper', 'onion', 'oil', 'chicken', 'mushroom', 'salt', 'soy_sauce', 'clove']] {'beef', 'pepper', 'scallion'}\n",
      "0.18181818181818182 0.1\n",
      "[['pepper', 'oil', 'salt', 'potato', 'clove', 'onion', 'parsley']] {'beef', 'parsley'}\n",
      "0.22222222222222224 0.125\n",
      "[['oil', 'onion', 'pepper', 'soy_sauce', 'sugar', 'chicken', 'vinegar']] {'garlic', 'beef', 'parsley', 'chili'}\n",
      "0 0\n",
      "[['pepper', 'oil', 'onion', 'salt', 'soy_sauce', 'clove']] {'beef', 'parsley', 'cucumb'}\n",
      "0 0\n",
      "[['oil', 'pepper', 'onion', 'clove', 'soy_sauce', 'ginger', 'sugar']] {'beef', 'pepper'}\n",
      "0.22222222222222224 0.125\n",
      "[['onion', 'soy_sauce', 'sugar', 'sake', 'water', 'mirin', 'stock', 'oil']] {'beef', 'parsley'}\n",
      "0 0\n",
      "[['oil', 'pepper', 'soy_sauce', 'clove', 'onion', 'ginger', 'sugar']] {'celeri', 'beef'}\n",
      "0 0\n",
      "[['oil', 'pepper', 'soy_sauce', 'clove', 'onion', 'sugar', 'beans', 'ginger', 'cornstarch']] {'celeri', 'beef'}\n",
      "0 0\n",
      "210\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "217\n",
      "218\n",
      "219\n",
      "411\n",
      "625\n",
      "626\n",
      "627\n",
      "930\n",
      "936\n",
      "937\n",
      "938\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "0.08515149114630126\n",
      "0.0494418024785674\n"
     ]
    }
   ],
   "source": [
    "# For 172 only\n",
    "\n",
    "f1_summary = []\n",
    "IOU_summary = []\n",
    "for i in range(0, len(results)):\n",
    "    \n",
    "    # validate\n",
    "#     generate_score = results.iloc[i][\"generate_score\"]\n",
    "#     if not is_recipe_validate(generate_score):\n",
    "#         continue\n",
    "        \n",
    "    # Evaluate the ingredient\n",
    "    generate_i = results.iloc[i][\"generate_ingre\"]\n",
    "    generate_ingre = [generate_i]\n",
    "    reference_ingre = get_tokenized_and_stemmed_list(results.iloc[i][\"ingredients\"], stemmed_ingre)\n",
    "    if i < 10:\n",
    "        print(generate_ingre,reference_ingre)\n",
    "\n",
    "    try:    \n",
    "        f1_score = score_ingre_f1(generate_ingre, reference_ingre)\n",
    "        iou_score = score_ingre_IOU(generate_ingre, reference_ingre)\n",
    "        f1_summary.append(f1_score)\n",
    "        IOU_summary.append(iou_score)\n",
    "    except:\n",
    "         print (i)\n",
    "\n",
    "    \n",
    "print(sum(f1_summary)/len(f1_summary))\n",
    "print(sum(IOU_summary)/len(IOU_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ct2020dl5787/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ct2020dl5787/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ct2020dl5787/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2725867782706981\n",
      "0.1717123872443988\n",
      "0.1220253762729777\n",
      "0.014463251029724216\n"
     ]
    }
   ],
   "source": [
    "# For Recipe 1M only\n",
    "\n",
    "n_bleu = 4 # bleu-n score, 4 is default\n",
    "f1_summary = []\n",
    "IOU_summary = []\n",
    "meteor_summary = []\n",
    "bleu_summary = []\n",
    "for i in range(0, len(results)):\n",
    "    \n",
    "    # validate\n",
    "    generate_score = results.iloc[i][\"generate_score\"]\n",
    "    if not is_recipe_validate(generate_score):\n",
    "        continue\n",
    "        \n",
    "    # Evaluate the ingredient\n",
    "    generate_ingre = results.iloc[i][\"generate_ingre\"]\n",
    "    reference_ingre = get_tokenized_and_stemmed_list(results.iloc[i][\"ingredients\"], stemmed_ingre)\n",
    "    f1_score = score_ingre_f1(generate_ingre, reference_ingre)\n",
    "    iou_score = score_ingre_IOU(generate_ingre, reference_ingre)\n",
    "    \n",
    "#     print(\"F-1 score\", f1_score)\n",
    "#     print(\"IOU score\", iou_score)\n",
    "    \n",
    "    # Evaluate the recipe\n",
    "    generate_recipes = results.iloc[i][\"generate_reci\"]\n",
    "    ref_recipe = results.iloc[i][\"instructions\"]\n",
    "    m_score = score_recipe_meteor(generate_recipes, ref_recipe)\n",
    "    bleu_score = score_blue_n(generate_recipes, ref_recipe, n_bleu)\n",
    "#     print(\"Meteor score\", m_score)\n",
    "#     print(\"Bleu score\", bleu_score)\n",
    "\n",
    "#     if(bleu_score < 0.05):\n",
    "#         print (i)\n",
    "#         print (bleu_score)\n",
    "#         print (generate_recipes)\n",
    "#         print (ref_recipe)\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    f1_summary.append(f1_score)\n",
    "    IOU_summary.append(iou_score)\n",
    "    meteor_summary.append(m_score)\n",
    "    bleu_summary.append(bleu_score)\n",
    "    \n",
    "print(sum(f1_summary)/len(f1_summary))\n",
    "print(sum(IOU_summary)/len(IOU_summary))\n",
    "print(sum(meteor_summary)/len(meteor_summary))\n",
    "print(sum(bleu_summary)/len(bleu_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Preheat oven to 350 degrees.',\n",
       "  'In a large bowl, combine flour, baking soda and salt.',\n",
       "  'In a separate bowl, beat together peanut butter, oil, sugar and egg.',\n",
       "  'Add to dry ingredients and mix well.',\n",
       "  'Drop by rounded teaspoonfuls onto ungreased cookie sheets.',\n",
       "  'Bake for 8-10 minutes.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[2][\"generate_reci\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Put ingredients in a buttered 9 x 12 x 2-inch pan in even layers in the order that they are given - DO NOT MIX.',\n",
       " 'Bake in a 350 oven for 1 hour.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[2][\"instructions\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
